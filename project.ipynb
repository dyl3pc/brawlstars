{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37564bitbasecondaf5e7dff0abbd4ccebbc48c8ce1ea7a61",
   "display_name": "Python 3.7.5 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from dateutil import tz\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import math\n",
    "import itertools\n",
    "import my_transformers\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns in the data frame [\"brawler\", \"trophies\", \"power\", \"highestTotalTrophies\", \"totalTrophies\", \"exp\", \"highestPowerPlay\", \"3vs3Victories\", \"soloVictories\", \"duoVictories\", \"highestBrawlerTrophies\"]\n",
    "\n",
    "battle_logs = pd.read_csv(\"data/cleaned_data.csv\")\n",
    "battle_logs = battle_logs[battle_logs[\"result\"] != \"draw\"]\n",
    "y = [1 if result == \"victory\" else 0 for result in battle_logs[\"result\"]]\n",
    "battle_logs.drop(\"result\", axis = 1, inplace = True)\n",
    "\n",
    "simple_battle_logs = my_transformers.ColumnSelector().fit_transform(battle_logs)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(simple_battle_logs, y, test_size = 0.2, random_state = 42)\n",
    "# X_test.to_csv(\"data/X_test.csv\", index = False)\n",
    "# pd.Series(y_test).to_csv(\"data/y_test.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Developing some baseline measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = []\n",
    "numeric_columns = []\n",
    "for col_name in X_train.columns:\n",
    "    if simple_battle_logs[col_name].dtype == 'O':\n",
    "        categorical_columns.append(col_name)\n",
    "    else:\n",
    "        numeric_columns.append(col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sgd</th>\n      <th>svc</th>\n      <th>rf</th>\n      <th>knn</th>\n      <th>lr</th>\n      <th>ensmble</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.646034</td>\n      <td>0.654172</td>\n      <td>0.653714</td>\n      <td>0.603508</td>\n      <td>0.653026</td>\n      <td>0.654172</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.645420</td>\n      <td>0.663762</td>\n      <td>0.658604</td>\n      <td>0.611716</td>\n      <td>0.657687</td>\n      <td>0.661470</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.648974</td>\n      <td>0.663075</td>\n      <td>0.663075</td>\n      <td>0.602545</td>\n      <td>0.668463</td>\n      <td>0.666858</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "        sgd       svc        rf       knn        lr   ensmble\n0  0.646034  0.654172  0.653714  0.603508  0.653026  0.654172\n1  0.645420  0.663762  0.658604  0.611716  0.657687  0.661470\n2  0.648974  0.663075  0.663075  0.602545  0.668463  0.666858"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This model drops all the brawler information. It only takes into account trophy information.\n",
    "\n",
    "numeric_pipe = Pipeline([\n",
    "    ('imputer', my_transformers.SpecialImputer()), # impute missing values by taking the median of the other players in that game\n",
    "    ('simple_imputer', SimpleImputer(strategy = \"median\")), # if there are other missing values fill them in\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipe = Pipeline([\n",
    "    ('drop_categorical_columns', my_transformers.DropCategoricalColumns()) # drop the original categorical variable\n",
    "])\n",
    "\n",
    "preprocess_pipe = ColumnTransformer([\n",
    "    (\"numeric_pipe\", numeric_pipe, numeric_columns),\n",
    "    (\"categorical_pipe\", categorical_pipe, categorical_columns)\n",
    "])\n",
    "\n",
    "\n",
    "pre_X_train = preprocess_pipe.fit_transform(X_train)\n",
    "\n",
    "models = [\n",
    "    (\"sgd\", SGDClassifier(random_state = 42)),\n",
    "    (\"svc\", SVC()),\n",
    "    (\"rf\", RandomForestClassifier()),\n",
    "    (\"knn\", KNeighborsClassifier()),\n",
    "    (\"lr\", LogisticRegression())\n",
    "]\n",
    "all_models = models + [(\"ensmble\", VotingClassifier(models, voting=\"hard\"))]\n",
    "\n",
    "results = {model[0] : cross_val_score(model[1], pre_X_train, y_train, cv = 3, scoring = \"accuracy\") for model in all_models}\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sgd</th>\n      <th>svc</th>\n      <th>rf</th>\n      <th>knn</th>\n      <th>lr</th>\n      <th>ensmble</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.665864</td>\n      <td>0.674347</td>\n      <td>0.659101</td>\n      <td>0.604081</td>\n      <td>0.673544</td>\n      <td>0.672169</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.669494</td>\n      <td>0.678895</td>\n      <td>0.664336</td>\n      <td>0.612977</td>\n      <td>0.682907</td>\n      <td>0.684054</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.666743</td>\n      <td>0.675800</td>\n      <td>0.665941</td>\n      <td>0.609767</td>\n      <td>0.676487</td>\n      <td>0.681532</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "        sgd       svc        rf       knn        lr   ensmble\n0  0.665864  0.674347  0.659101  0.604081  0.673544  0.672169\n1  0.669494  0.678895  0.664336  0.612977  0.682907  0.684054\n2  0.666743  0.675800  0.665941  0.609767  0.676487  0.681532"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this code also takes into account categorical variables which the categorical variables are simply one_hot encoded\n",
    "\n",
    "numeric_pipe = Pipeline([\n",
    "    ('imputer', my_transformers.SpecialImputer()), # impute missing values by taking the median of the other players in that game\n",
    "    ('simple_imputer', SimpleImputer(strategy = \"median\")), # if there are other missing values fill them in\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipe = Pipeline([\n",
    "    ('one_hot_encoder', my_transformers.MyOneHotEncoder()), # one hot encode the brawlers of each player\n",
    "    ('drop_categorical_columns', my_transformers.DropCategoricalColumns()) # drop the original categorical variable\n",
    "])\n",
    "\n",
    "preprocess_pipe = ColumnTransformer([\n",
    "    (\"numeric_pipe\", numeric_pipe, numeric_columns),\n",
    "    (\"categorical_pipe\", categorical_pipe, categorical_columns)\n",
    "])\n",
    "\n",
    "\n",
    "pre_X_train = preprocess_pipe.fit_transform(X_train)\n",
    "\n",
    "models = [\n",
    "    (\"sgd\", SGDClassifier(random_state = 42, max_iter = 10000)),\n",
    "    (\"svc\", SVC()),\n",
    "    (\"rf\", RandomForestClassifier()),\n",
    "    (\"knn\", KNeighborsClassifier()),\n",
    "    (\"lr\", LogisticRegression(max_iter = 10000))\n",
    "]\n",
    "all_models = models + [(\"ensmble\", VotingClassifier(models, voting=\"hard\"))]\n",
    "\n",
    "results = {model[0] : cross_val_score(model[1], pre_X_train, y_train, cv = 3, scoring = \"accuracy\") for model in all_models}\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optimizing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "C:\\Users\\student\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  This is separate from the ipykernel package so we can avoid doing imports until\nc:\\Users\\student\\Desktop\\brawlstars\\my_transformers.py:123: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\nof pandas will change to not sort by default.\n\nTo accept the future behavior, pass 'sort=False'.\n\nTo retain the current behavior and silence the warning, pass 'sort=True'.\n\n  X = pd.concat(all_Xs)\n"
    }
   ],
   "source": [
    "# artifically increase the number of samples by 72 fold\n",
    "X, X_val, y, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state = 42)\n",
    "X[\"result\"] = y\n",
    "X, y = my_transformers.DataImputer().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(pd.read_csv(\"data/pre_X_imputed.csv\"))\n",
    "y = np.array(pd.read_csv(\"data/pre_y_imputed.csv\"))\n",
    "pre_X_val = np.array(pd.read_csv(\"data/pre_X_val.csv\"))\n",
    "y_val = np.array(pd.read_csv(\"data/pre_y_val.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "source": [
    "numeric_pipe = Pipeline([\n",
    "    ('imputer', my_transformers.SpecialImputer()), # impute missing values by taking the median of the other players in that game\n",
    "    ('simple_imputer', SimpleImputer(strategy = \"median\")), # if there are other missing values fill them in\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipe = Pipeline([\n",
    "    ('one_hot_encoder', my_transformers.MyOneHotEncoder()), # one hot encode the brawlers of each player\n",
    "    ('drop_categorical_columns', my_transformers.DropCategoricalColumns()) # drop the original categorical variable\n",
    "])\n",
    "\n",
    "preprocess_pipe = ColumnTransformer([\n",
    "    (\"numeric_pipe\", numeric_pipe, numeric_columns),\n",
    "    (\"categorical_pipe\", categorical_pipe, categorical_columns)\n",
    "])\n",
    "\n",
    "\n",
    "pre_X = preprocess_pipe.fit_transform(X)\n",
    "y = np.array(y)\n",
    "pre_X_val = preprocess_pipe.transform(X_val)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pre_X).to_csv(\"data/pre_X.csv\")\n",
    "pd.DataFrame(y).to_csv(\"data/y.csv\")\n",
    "pd.DataFrame(pre_X_val).to_csv(\"data/pre_X_val.csv\")\n",
    "pd.DataFrame(y_val).to_csv(\"data/y_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"sgd\", SGDClassifier(random_state = 42, max_iter = 10000)),\n",
    "    # (\"rf\", RandomForestClassifier()),\n",
    "    (\"lr\", LogisticRegression(max_iter = 10000))\n",
    "]\n",
    "all_models = models + [(\"ensmble\", VotingClassifier(models, voting=\"hard\"))]\n",
    "\n",
    "all_trained_models = [(model[0], model[1].fit(pre_X, y)) for model in all_models]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "all_trained_models_accuracy = [(model[0], accuracy_score(model[1].predict(pre_X_val), y_val)) for model in all_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[('sgd', 0.6820787160871227),\n ('lr', 0.6878104700038211),\n ('ensmble', 0.6839893007260222)]"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trained_models_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 1507392 samples, validate on 5234 samples\nEpoch 1/5\n1507392/1507392 [==============================] - 217s 144us/sample - loss: 0.5849 - accuracy: 0.6837 - val_loss: 0.5827 - val_accuracy: 0.6916\nEpoch 2/5\n1507392/1507392 [==============================] - 184s 122us/sample - loss: 0.5760 - accuracy: 0.6922 - val_loss: 0.5817 - val_accuracy: 0.6958\nEpoch 3/5\n1507392/1507392 [==============================] - 205s 136us/sample - loss: 0.5697 - accuracy: 0.6977 - val_loss: 0.5832 - val_accuracy: 0.6905\nEpoch 4/5\n1507392/1507392 [==============================] - 187s 124us/sample - loss: 0.5617 - accuracy: 0.7039 - val_loss: 0.5862 - val_accuracy: 0.6888\nEpoch 5/5\n1507392/1507392 [==============================] - 193s 128us/sample - loss: 0.5517 - accuracy: 0.7123 - val_loss: 0.5967 - val_accuracy: 0.6769\n"
    }
   ],
   "source": [
    "# without trying to impute any more data; try to get a neural net to work as well as SVM\n",
    "model1 = keras.models.Sequential([\n",
    "    keras.layers.Dense(228, input_shape = (228,)),\n",
    "    keras.layers.Dense(448, activation = \"relu\"),\n",
    "    # keras.layers.Dense(114, activation = \"relu\"),\n",
    "    keras.layers.Dense(1, activation = \"sigmoid\")\n",
    "])\n",
    "model1.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer = \"sgd\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = model1.fit(pre_X, y, epochs = 5, validation_data = (pre_X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 1507392 samples, validate on 5234 samples\nEpoch 1/5\n1507392/1507392 [==============================] - 166s 110us/sample - loss: 0.5856 - accuracy: 0.6827 - val_loss: 0.5823 - val_accuracy: 0.6914\nEpoch 2/5\n1507392/1507392 [==============================] - 167s 111us/sample - loss: 0.5771 - accuracy: 0.6911 - val_loss: 0.5814 - val_accuracy: 0.6941\nEpoch 3/5\n1507392/1507392 [==============================] - 181s 120us/sample - loss: 0.5721 - accuracy: 0.6953 - val_loss: 0.5822 - val_accuracy: 0.6916\nEpoch 4/5\n1507392/1507392 [==============================] - 172s 114us/sample - loss: 0.5663 - accuracy: 0.7002 - val_loss: 0.5833 - val_accuracy: 0.6901\nEpoch 5/5\n1507392/1507392 [==============================] - 178s 118us/sample - loss: 0.5599 - accuracy: 0.7057 - val_loss: 0.5873 - val_accuracy: 0.6838\n"
    }
   ],
   "source": [
    "# without trying to impute any more data; try to get a neural net to work as well as SVM\n",
    "model2 = keras.models.Sequential([\n",
    "    keras.layers.Dense(228, input_shape = (228,)),\n",
    "    keras.layers.Dense(114, activation = \"relu\"),\n",
    "    # keras.layers.Dense(114, activation = \"relu\"),\n",
    "    keras.layers.Dense(1, activation = \"sigmoid\")\n",
    "])\n",
    "model2.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer = \"sgd\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = model2.fit(pre_X, y, epochs = 5, validation_data = (pre_X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 1507392 samples, validate on 5234 samples\nEpoch 1/5\n1507392/1507392 [==============================] - 186s 123us/sample - loss: 0.5868 - accuracy: 0.6806 - val_loss: 0.5834 - val_accuracy: 0.6890\nEpoch 2/5\n1507392/1507392 [==============================] - 186s 123us/sample - loss: 0.5775 - accuracy: 0.6901 - val_loss: 0.5814 - val_accuracy: 0.6941\nEpoch 3/5\n1507392/1507392 [==============================] - 183s 122us/sample - loss: 0.5728 - accuracy: 0.6940 - val_loss: 0.5831 - val_accuracy: 0.6930\nEpoch 4/5\n1507392/1507392 [==============================] - 179s 119us/sample - loss: 0.5672 - accuracy: 0.6985 - val_loss: 0.5879 - val_accuracy: 0.6928\nEpoch 5/5\n1507392/1507392 [==============================] - 185s 123us/sample - loss: 0.5606 - accuracy: 0.7044 - val_loss: 0.5913 - val_accuracy: 0.6863\n"
    }
   ],
   "source": [
    "# without trying to impute any more data; try to get a neural net to work as well as SVM\n",
    "model3 = keras.models.Sequential([\n",
    "    keras.layers.Dense(228, input_shape = (228,)),\n",
    "    keras.layers.Dense(50, activation = \"relu\"),\n",
    "    keras.layers.Dense(25, activation = \"relu\"),\n",
    "    keras.layers.Dense(1, activation = \"sigmoid\")\n",
    "])\n",
    "model3.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer = \"sgd\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = model3.fit(pre_X, y, epochs = 5, validation_data = (pre_X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.681289347391617"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_X_test = preprocess_pipe.transform(X_test)\n",
    "model = models[0][1]\n",
    "score = accuracy_score(model.predict(np.array(pre_X_test)), np.array(y_test))\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
